<h1 align="center">Statistics and Computer Science Student at Elon University</h1>

- üë®‚Äçüíª All of my projects are available [here](https://github.com/annarakes?tab=repositories)

- üå± I‚Äôm currently learning **Calculus II, Computer Science II, Discrete Structures**

- üìù I'm currently working on my thesis: **A Systematic Review of the Effects of Magnet Schools on Desegregation**

- üì´ How to reach me: **arakes@elon.edu**


**Connect with me:**

[<img src="images/linkedin.png" width="60" height="60">](www.linkedin.com/in/anna-rakes-a6780129a)



## Elon University, Class of 2026

### GPA: 4.0

**B.S. in Statistics with a concentration in Data Analytics**

**B.A. in Computer Science**

### Achievements

Honors Fellows Program

Fall 2022-Fall 2024 President‚Äôs List 

Mu Sigma Rho National Statistics Honor Society

### Completed Courses:

Calculus I, Statistical Modeling, Survey Sampling Methods, Intro to Data Analytics, Methods for Data Analytics, Computer Science I, Statistical Computing Simulation Theory, Statistical Computing & Data Management	

### Skills

Python, Java, R-Studio, SAS, Excel

## Projects

**[R Studio Data Cleaning & Visualization Replication Project](https://github.com/annarakes/RStudio-DataReplication.git)**

The objective of this project was to replicate the results of Comeau's analysis without access to the cleaned data set Comeau used. I only had access to the final report, using the methods and results to determine how to clean the large GSS dataset in order to achieve a dataset that was the same as Comeau's and produce the same results. Using R-Studio and the GSS dataset, I focused on the variables impact of race, sex, marital status, geographic mobility, and family contact patterns. To achieve this, I filtered the dataset to include only respondents from 2002 aged 18 and older, and then narrowed down the data to variables used in Comeau's analysis. I carefully selected race variables (RACECEN1, RACECEN2, and RACECEN3) to include only White, Black, and Hispanic respondents, and created race dummy variables, as well as dummy variables for sex, marital status, and geographic mobility. I recoded family-related variables to combine responses and create family contact indexes for nuclear and extended families. After ensuring proper data cleaning, including converting certain variables to numeric types, I ran regression models to predict family contact frequencies. I compared my results to Comeau's by checking key statistics, such as R¬≤, coefficients, and significance levels, finding some slight discrepancies due to differences in race distribution and sample size, but overall similar results.

**[R Studio Shiny App Simulation Project](https://github.com/annarakes/RStudio-ShinyAppSimulation.git)**

The objective of this project was to develop an interactive Shiny web application that allows users to visualize Normal and T-distributions and calculate p-values based on various inputs. In the app, users can choose between a Normal or T-distribution, input a test statistic, select the direction for the p-value (two-tailed, left, or right), and for the T-distribution, input degrees of freedom. I implemented the UI to capture user inputs and the server logic to generate corresponding plots using ggplot2, highlighting the critical regions, and calculating the p-values based on the chosen inputs. Key steps involved defining the UI components for user interactions, using conditional statements to adjust plots and calculations based on user input, and utilizing statistical functions like pnorm and pt to compute p-values for the selected distributions.


**[Python Yahtzee Project](https://github.com/annarakes/Python-Yahtzee.git)**

The objective of this project was to develop a Yahtzee game, including the core game logic and necessary helper functions for scorekeeping and dice rolls. I implemented several helper functions in yahtzeeHelper.py to manage the scorecard, perform dice rolls, and handle user input for keeping or rerolling dice. Additionally, I created unit tests in yahtzeeUnitTests.py to verify the functionality of these helper functions, such as initializing and printing the scorecard, rolling dice, and calculating scores for different categories. I also outlined the necessary steps to implement scoring logic in yahtzee.py, such as calculating specific category scores (e.g., "Three of a Kind", "Full House") and handling user selections to score their rolls. Through these steps, I ensured that all the game's mechanics and scoring rules were systematically tested and implemented.

**[Python BlackJack Project](https://github.com/annarakes/Python-BlackJack.git)**

The objective of this project was to develop a text-based Blackjack game where the player competes against a dealer or a computer. I implemented key game mechanics such as deck creation, card shuffling, dealing, score calculation, and turn management. I began by creating a deck of cards using a combination of suits and values, then shuffled it randomly. I programmed functions to deal cards to players, calculate scores based on the card values, and determine whether players or the dealer should hit or stand based on their score. Additionally, I created a system to determine the winner based on the final scores and incorporated replay functionality. The game supports both 1-player and 2-player modes, offering an engaging, interactive experience with decision-making for the user.

**[SAS Data Cleaning & Visualization Projects](https://github.com/annarakes/SAS-DataCleaning.git)**

The objective of this project was to analyze pain severity trends and treatment effectiveness in a clinical study using patient baseline and follow-up data. As part of this data analytics project, I focused on importing and cleaning the dataset, handling missing values, and creating new variables such as BMI, pain severity scores, and treatment effects. I performed exploratory data analysis to uncover insights into how pain severity varied by race, gender, and treatment group. Using SAS, I created visualizations like box plots to show baseline pain severity distributions and line plots to track pain severity trends over time across different treatment groups. Key steps included merging datasets, calculating summary statistics, and transforming the data into a clean format for further analysis, with a final goal of preparing a comprehensive dataset that could be used for deeper statistical analysis or predictive modeling.





